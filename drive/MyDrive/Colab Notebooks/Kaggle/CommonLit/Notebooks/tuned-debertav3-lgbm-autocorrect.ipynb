{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# Notes\n","This is a slightly tuned version of @nogawanogawa 's work and I have also converted his messages to english here you can find his notebook here https://www.kaggle.com/code/tsunotsuno/updated-debertav3-lgbm-with-spell-autocorrect please give him kudos for sharing his efforts\n","\n","### Things I would expect there to be a number of things that will allow this model to preform better outside of just strategy and more data. I would imagine there are a few more tuning parameters that could help this model go a long way.\n","\n","\n","\n","\n","\n","In this notebook a combonation of Deberta and LGBM is used, pyspellchecker is also used in order to correct some of the spelling mistakes that are discussed in the discussions tab\n","[Discussion Link](https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/discussion/428941).\n","[my previous notebook](https://www.kaggle.com/code/tsunotsuno/debertav3-lgbm-with-feature-engineering)\n","[Discussion Link](https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/discussion/428941).\n","\n","The primary goal of this notebook is to enhance the overall score by honing in on the issue of \"misspellings.\"\n","\n","## Main Concept\n","\n","The Transformers model I'm currently utilizing, Deberta, is pretrained on \"correct sentences.\" However, if I were to train and input it with sentences containing misspellings, Deberta's ability to understand meaning might be compromised.\n","\n","From a human evaluator's perspective, detecting misspellings would prompt deductions in scores. After discreetly rectifying the misspelled words, I'd proceed to evaluate other textual facets. If we assume the scoring process aligns with this approach, it's conceivable that tallying and **correcting** misspellings before feeding text into Deberta could enable the model to aptly capture features beyond just misspellings.\n","\n","In this notebook, I will embark on the journey of auto-correcting misspelled words before inputting them into Deberta. The aim is to evaluate the model's performance by distinctly isolating misspellings from other aspects.\n","\n","### Feature Engineering\n","\n","I intend to largely retain the same features as before:\n","\n","- Text Length\n","- Length Ratio\n","- Word Overlap\n","- N-grams Co-occurrence\n","  - Count\n","  - Ratio\n","- Quotes Overlap\n","- Grammar Check\n","  - Spelling: pyspellchecker\n","\n","### Model Architecture\n","\n","I plan to construct a model with the architecture depicted in the following diagram. For the input to Deberta (`text`), I will pre-process by correcting any misspellings. In other aspects of feature engineering, I will utilize the `text` as is.\n","\n","![image.png](attachment:ff0ac1de-519e-4239-8a78-3386acc3e551.png)\n","\n","### References\n","\n","- https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/discussion/428941\n","\n","### My previous notebooks\n","\n","- https://www.kaggle.com/code/tsunotsuno/debertav3-baseline-content-and-wording-models\n","- https://www.kaggle.com/code/tsunotsuno/debertav3-w-prompt-title-question-fields\n","- https://www.kaggle.com/code/tsunotsuno/debertav3-with-llama2-example\n","- https://www.kaggle.com/code/tsunotsuno/debertav3-lgbm-with-feature-engineering\n"],"metadata":{"id":"d2RWIMO746eR"}},{"cell_type":"code","source":["!pip install \"/kaggle/input/autocorrect/autocorrect-2.6.1.tar\"\n","!pip install \"/kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\""],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"OQ7ZZLRd46eU","executionInfo":{"status":"ok","timestamp":1695268734657,"user_tz":-540,"elapsed":2203,"user":{"displayName":"大野篤史","userId":"02236911886434017815"}},"outputId":"219dcb3c-23ac-4e07-f326-106b47bb7e6f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Requirement '/kaggle/input/autocorrect/autocorrect-2.6.1.tar' looks like a filename, but the file does not exist\u001b[0m\u001b[33m\n","\u001b[0mProcessing /kaggle/input/autocorrect/autocorrect-2.6.1.tar\n","\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/kaggle/input/autocorrect/autocorrect-2.6.1.tar'\n","\u001b[0m\u001b[31m\n","\u001b[0m\u001b[33mWARNING: Requirement '/kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl' looks like a filename, but the file does not exist\u001b[0m\u001b[33m\n","\u001b[0mProcessing /kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\n","\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl'\n","\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["from typing import List\n","import numpy as np\n","import pandas as pd\n","import warnings\n","import logging\n","import os\n","import shutil\n","import json\n","import transformers\n","from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n","from transformers import DataCollatorWithPadding\n","from datasets import Dataset,load_dataset, load_from_disk\n","from transformers import TrainingArguments, Trainer\n","from datasets import load_metric, disable_progress_bar\n","from sklearn.metrics import mean_squared_error\n","import torch\n","from sklearn.model_selection import KFold, GroupKFold\n","from tqdm import tqdm\n","\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.tokenize.treebank import TreebankWordDetokenizer\n","from collections import Counter\n","import spacy\n","import re\n","from autocorrect import Speller\n","from spellchecker import SpellChecker\n","import lightgbm as lgb\n","\n","warnings.simplefilter(\"ignore\")\n","logging.disable(logging.ERROR)\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","disable_progress_bar()\n","tqdm.pandas()"],"metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":396},"id":"jLIrEFtx46eV","executionInfo":{"status":"error","timestamp":1695268762290,"user_tz":-540,"elapsed":954,"user":{"displayName":"大野篤史","userId":"02236911886434017815"}},"outputId":"b448f717-2d71-4cc1-cd7b-f323b202a2a6"},"execution_count":2,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-ef8dd8b7d7be>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataCollatorWithPadding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["def seed_everything(seed: int):\n","    import random, os\n","    import numpy as np\n","    import torch\n","\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","seed_everything(seed=42)"],"metadata":{"trusted":true,"id":"oJGvq-5246eW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CFG:\n","    model_name=\"debertav3base\"\n","    learning_rate=0.000016   #0.000015\n","    weight_decay=0.03        #0.02\n","    hidden_dropout_prob=0.007\n","    attention_probs_dropout_prob=0.007\n","    num_train_epochs=5\n","    n_splits=4\n","    batch_size=12\n","    random_seed=42\n","    save_steps=100\n","    max_length=512"],"metadata":{"trusted":true,"id":"_DRxKIjH46eW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Dataload"],"metadata":{"id":"_nds_CdR46eW"}},{"cell_type":"code","source":["DATA_DIR = \"/kaggle/input/commonlit-evaluate-student-summaries/\"\n","\n","prompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\n","prompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\n","summaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\n","summaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")\n","sample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")"],"metadata":{"trusted":true,"id":"DNrMBVSS46eX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Preprocess\n","\n","[Using features]\n","\n","- Text Length\n","- Length Ratio\n","- Word Overlap\n","- N-grams Co-occurrence\n","  - count\n","  - ratio\n","- Quotes Overlap\n","- Grammar Check\n","  - spelling: pyspellchecker\n"],"metadata":{"id":"xxx7hf0-46eX"}},{"cell_type":"code","source":["class Preprocessor:\n","    def __init__(self,\n","                model_name: str,\n","                ) -> None:\n","        self.tokenizer = AutoTokenizer.from_pretrained(f\"/kaggle/input/{model_name}\")\n","        self.twd = TreebankWordDetokenizer()\n","        self.STOP_WORDS = set(stopwords.words('english'))\n","\n","        self.spacy_ner_model = spacy.load('en_core_web_sm',)\n","        self.speller = Speller(lang='en')\n","        self.spellchecker = SpellChecker()\n","\n","    def word_overlap_count(self, row):\n","        \"\"\" intersection(prompt_text, text) \"\"\"\n","        def check_is_stop_word(word):\n","            return word in self.STOP_WORDS\n","\n","        prompt_words = row['prompt_tokens']\n","        summary_words = row['summary_tokens']\n","        if self.STOP_WORDS:\n","            prompt_words = list(filter(check_is_stop_word, prompt_words))\n","            summary_words = list(filter(check_is_stop_word, summary_words))\n","        return len(set(prompt_words).intersection(set(summary_words)))\n","\n","    def ngrams(self, token, n):\n","        # Use the zip function to help us generate n-grams\n","        # Concatentate the tokens into ngrams and return\n","        ngrams = zip(*[token[i:] for i in range(n)])\n","        return [\" \".join(ngram) for ngram in ngrams]\n","\n","    def ngram_co_occurrence(self, row, n: int) -> int:\n","        # Tokenize the original text and summary into words\n","        original_tokens = row['prompt_tokens']\n","        summary_tokens = row['summary_tokens']\n","\n","        # Generate n-grams for the original text and summary\n","        original_ngrams = set(self.ngrams(original_tokens, n))\n","        summary_ngrams = set(self.ngrams(summary_tokens, n))\n","\n","        # Calculate the number of common n-grams\n","        common_ngrams = original_ngrams.intersection(summary_ngrams)\n","        return len(common_ngrams)\n","\n","    def ner_overlap_count(self, row, mode:str):\n","        model = self.spacy_ner_model\n","        def clean_ners(ner_list):\n","            return set([(ner[0].lower(), ner[1]) for ner in ner_list])\n","        prompt = model(row['prompt_text'])\n","        summary = model(row['text'])\n","\n","        if \"spacy\" in str(model):\n","            prompt_ner = set([(token.text, token.label_) for token in prompt.ents])\n","            summary_ner = set([(token.text, token.label_) for token in summary.ents])\n","        elif \"stanza\" in str(model):\n","            prompt_ner = set([(token.text, token.type) for token in prompt.ents])\n","            summary_ner = set([(token.text, token.type) for token in summary.ents])\n","        else:\n","            raise Exception(\"Model not supported\")\n","\n","        prompt_ner = clean_ners(prompt_ner)\n","        summary_ner = clean_ners(summary_ner)\n","\n","        intersecting_ners = prompt_ner.intersection(summary_ner)\n","\n","        ner_dict = dict(Counter([ner[1] for ner in intersecting_ners]))\n","\n","        if mode == \"train\":\n","            return ner_dict\n","        elif mode == \"test\":\n","            return {key: ner_dict.get(key) for key in self.ner_keys}\n","\n","\n","    def quotes_count(self, row):\n","        summary = row['text']\n","        text = row['prompt_text']\n","        quotes_from_summary = re.findall(r'\"([^\"]*)\"', summary)\n","        if len(quotes_from_summary)>0:\n","            return [quote in text for quote in quotes_from_summary].count(True)\n","        else:\n","            return 0\n","\n","    def spelling(self, text):\n","\n","        wordlist=text.split()\n","        amount_miss = len(list(self.spellchecker.unknown(wordlist)))\n","\n","        return amount_miss\n","\n","    def add_spelling_dictionary(self, tokens: List[str]) -> List[str]:\n","        \"\"\"dictionary update for pyspell checker and autocorrect\"\"\"\n","        self.spellchecker.word_frequency.load_words(tokens)\n","        self.speller.nlp_data.update({token:1000 for token in tokens})\n","\n","    def run(self,\n","            prompts: pd.DataFrame,\n","            summaries:pd.DataFrame,\n","            mode:str\n","        ) -> pd.DataFrame:\n","\n","        # before merge preprocess\n","        prompts[\"prompt_length\"] = prompts[\"prompt_text\"].apply(\n","            lambda x: len(word_tokenize(x))\n","        )\n","        prompts[\"prompt_tokens\"] = prompts[\"prompt_text\"].apply(\n","            lambda x: word_tokenize(x)\n","        )\n","\n","        summaries[\"summary_length\"] = summaries[\"text\"].apply(\n","            lambda x: len(word_tokenize(x))\n","        )\n","        summaries[\"summary_tokens\"] = summaries[\"text\"].apply(\n","            lambda x: word_tokenize(x)\n","        )\n","\n","        # Add prompt tokens into spelling checker dictionary\n","        prompts[\"prompt_tokens\"].apply(\n","            lambda x: self.add_spelling_dictionary(x)\n","        )\n","\n","#         from IPython.core.debugger import Pdb; Pdb().set_trace()\n","        # fix misspelling\n","        summaries[\"fixed_summary_text\"] = summaries[\"text\"].progress_apply(\n","            lambda x: self.speller(x)\n","        )\n","\n","        # count misspelling\n","        summaries[\"splling_err_num\"] = summaries[\"text\"].progress_apply(self.spelling)\n","\n","        # merge prompts and summaries\n","        input_df = summaries.merge(prompts, how=\"left\", on=\"prompt_id\")\n","\n","        # after merge preprocess\n","        input_df['length_ratio'] = input_df['summary_length'] / input_df['prompt_length']\n","\n","        input_df['word_overlap_count'] = input_df.progress_apply(self.word_overlap_count, axis=1)\n","        input_df['bigram_overlap_count'] = input_df.progress_apply(\n","            self.ngram_co_occurrence,args=(2,), axis=1\n","        )\n","        input_df['bigram_overlap_ratio'] = input_df['bigram_overlap_count'] / (input_df['summary_length'] - 1)\n","\n","        input_df['trigram_overlap_count'] = input_df.progress_apply(\n","            self.ngram_co_occurrence, args=(3,), axis=1\n","        )\n","        input_df['trigram_overlap_ratio'] = input_df['trigram_overlap_count'] / (input_df['summary_length'] - 2)\n","\n","        input_df['quotes_count'] = input_df.progress_apply(self.quotes_count, axis=1)\n","\n","        return input_df.drop(columns=[\"summary_tokens\", \"prompt_tokens\"])\n","\n","preprocessor = Preprocessor(model_name=CFG.model_name)"],"metadata":{"trusted":true,"id":"0AHBwXDC46eX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train = preprocessor.run(prompts_train, summaries_train, mode=\"train\")\n","test = preprocessor.run(prompts_test, summaries_test, mode=\"test\")\n","\n","train.head()"],"metadata":{"trusted":true,"id":"NtEwr7Xo46eY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gkf = GroupKFold(n_splits=CFG.n_splits)\n","\n","for i, (_, val_index) in enumerate(gkf.split(train, groups=train[\"prompt_id\"])):\n","    train.loc[val_index, \"fold\"] = i\n","\n","train.head()"],"metadata":{"trusted":true,"id":"fBb0EXQP46eY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Model Function Definition"],"metadata":{"id":"DcT5rxxD46eY"}},{"cell_type":"code","source":["def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    rmse = mean_squared_error(labels, predictions, squared=False)\n","    return {\"rmse\": rmse}\n","\n","def compute_mcrmse(eval_pred):\n","    \"\"\"\n","    Calculates mean columnwise root mean squared error\n","    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n","    \"\"\"\n","    preds, labels = eval_pred\n","\n","    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n","    mcrmse = np.mean(col_rmse)\n","\n","    return {\n","        \"content_rmse\": col_rmse[0],\n","        \"wording_rmse\": col_rmse[1],\n","        \"mcrmse\": mcrmse,\n","    }\n","\n","def compt_score(content_true, content_pred, wording_true, wording_pred):\n","    content_score = mean_squared_error(content_true, content_pred)**(1/2)\n","    wording_score = mean_squared_error(wording_true, wording_pred)**(1/2)\n","\n","    return (content_score + wording_score)/2"],"metadata":{"trusted":true,"id":"sCQFG7Rk46eY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Deberta Regressor"],"metadata":{"id":"M35tol1b46eZ"}},{"cell_type":"code","source":["class ContentScoreRegressor:\n","    def __init__(self,\n","                model_name: str,\n","                model_dir: str,\n","                target: str,\n","                hidden_dropout_prob: float,\n","                attention_probs_dropout_prob: float,\n","                max_length: int,\n","                ):\n","        self.inputs = [\"prompt_text\", \"prompt_title\", \"prompt_question\", \"fixed_summary_text\"]\n","        self.input_col = \"input\"\n","\n","        self.text_cols = [self.input_col]\n","        self.target = target\n","        self.target_cols = [target]\n","\n","        self.model_name = model_name\n","        self.model_dir = model_dir\n","        self.max_length = max_length\n","\n","        self.tokenizer = AutoTokenizer.from_pretrained(f\"/kaggle/input/{model_name}\")\n","        self.model_config = AutoConfig.from_pretrained(f\"/kaggle/input/{model_name}\")\n","\n","        self.model_config.update({\n","            \"hidden_dropout_prob\": hidden_dropout_prob,\n","            \"attention_probs_dropout_prob\": attention_probs_dropout_prob,\n","            \"num_labels\": 1,\n","            \"problem_type\": \"regression\",\n","        })\n","\n","        seed_everything(seed=42)\n","\n","        self.data_collator = DataCollatorWithPadding(\n","            tokenizer=self.tokenizer\n","        )\n","\n","\n","    def tokenize_function(self, examples: pd.DataFrame):\n","        labels = [examples[self.target]]\n","        tokenized = self.tokenizer(examples[self.input_col],\n","                         padding=False,\n","                         truncation=True,\n","                         max_length=self.max_length)\n","        return {\n","            **tokenized,\n","            \"labels\": labels,\n","        }\n","\n","    def tokenize_function_test(self, examples: pd.DataFrame):\n","        tokenized = self.tokenizer(examples[self.input_col],\n","                         padding=False,\n","                         truncation=True,\n","                         max_length=self.max_length)\n","        return tokenized\n","\n","    def train(self,\n","            fold: int,\n","            train_df: pd.DataFrame,\n","            valid_df: pd.DataFrame,\n","            batch_size: int,\n","            learning_rate: float,\n","            weight_decay: float,\n","            num_train_epochs: float,\n","            save_steps: int,\n","        ) -> None:\n","        \"\"\"fine-tuning\"\"\"\n","\n","        sep = self.tokenizer.sep_token\n","        train_df[self.input_col] = (\n","                    train_df[\"prompt_title\"] + sep\n","                    + train_df[\"prompt_question\"] + sep\n","                    + train_df[\"fixed_summary_text\"]\n","                  )\n","\n","        valid_df[self.input_col] = (\n","                    valid_df[\"prompt_title\"] + sep\n","                    + valid_df[\"prompt_question\"] + sep\n","                    + valid_df[\"fixed_summary_text\"]\n","                  )\n","\n","        train_df = train_df[[self.input_col] + self.target_cols]\n","        valid_df = valid_df[[self.input_col] + self.target_cols]\n","\n","        model_content = AutoModelForSequenceClassification.from_pretrained(\n","            f\"/kaggle/input/{self.model_name}\",\n","            config=self.model_config\n","        )\n","\n","        train_dataset = Dataset.from_pandas(train_df, preserve_index=False)\n","        val_dataset = Dataset.from_pandas(valid_df, preserve_index=False)\n","\n","        train_tokenized_datasets = train_dataset.map(self.tokenize_function, batched=False)\n","        val_tokenized_datasets = val_dataset.map(self.tokenize_function, batched=False)\n","\n","        # eg. \"bert/fold_0/\"\n","        model_fold_dir = os.path.join(self.model_dir, str(fold))\n","\n","        training_args = TrainingArguments(\n","            output_dir=model_fold_dir,\n","            load_best_model_at_end=True, # select best model\n","            learning_rate=learning_rate,\n","            per_device_train_batch_size=batch_size,\n","            per_device_eval_batch_size=8,\n","            num_train_epochs=num_train_epochs,\n","            weight_decay=weight_decay,\n","            report_to='none',\n","            greater_is_better=False,\n","            save_strategy=\"steps\",\n","            evaluation_strategy=\"steps\",\n","            eval_steps=save_steps,\n","            save_steps=save_steps,\n","            metric_for_best_model=\"rmse\",\n","            save_total_limit=1\n","        )\n","\n","        trainer = Trainer(\n","            model=model_content,\n","            args=training_args,\n","            train_dataset=train_tokenized_datasets,\n","            eval_dataset=val_tokenized_datasets,\n","            tokenizer=self.tokenizer,\n","            compute_metrics=compute_metrics,\n","            data_collator=self.data_collator\n","        )\n","\n","        trainer.train()\n","\n","        model_content.save_pretrained(self.model_dir)\n","        self.tokenizer.save_pretrained(self.model_dir)\n","\n","\n","    def predict(self,\n","                test_df: pd.DataFrame,\n","                fold: int,\n","               ):\n","        \"\"\"predict content score\"\"\"\n","\n","        sep = self.tokenizer.sep_token\n","        in_text = (\n","                    test_df[\"prompt_title\"] + sep\n","                    + test_df[\"prompt_question\"] + sep\n","                    + test_df[\"fixed_summary_text\"]\n","                  )\n","        test_df[self.input_col] = in_text\n","\n","        test_ = test_df[[self.input_col]]\n","\n","        test_dataset = Dataset.from_pandas(test_, preserve_index=False)\n","        test_tokenized_dataset = test_dataset.map(self.tokenize_function_test, batched=False)\n","\n","        model_content = AutoModelForSequenceClassification.from_pretrained(f\"{self.model_dir}\")\n","        model_content.eval()\n","\n","        # e.g. \"bert/fold_0/\"\n","        model_fold_dir = os.path.join(self.model_dir, str(fold))\n","\n","        test_args = TrainingArguments(\n","            output_dir=model_fold_dir,\n","            do_train = False,\n","            do_predict = True,\n","            per_device_eval_batch_size = 4,\n","            dataloader_drop_last = False,\n","        )\n","\n","        # init trainer\n","        infer_content = Trainer(\n","                      model = model_content,\n","                      tokenizer=self.tokenizer,\n","                      data_collator=self.data_collator,\n","                      args = test_args)\n","\n","        preds = infer_content.predict(test_tokenized_dataset)[0]\n","\n","        return preds"],"metadata":{"trusted":true,"id":"2vb37_Kc46eZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_by_fold(\n","        train_df: pd.DataFrame,\n","        model_name: str,\n","        target:str,\n","        save_each_model: bool,\n","        n_splits: int,\n","        batch_size: int,\n","        learning_rate: int,\n","        hidden_dropout_prob: float,\n","        attention_probs_dropout_prob: float,\n","        weight_decay: float,\n","        num_train_epochs: int,\n","        save_steps: int,\n","        max_length:int\n","    ):\n","\n","    # delete old model files\n","    if os.path.exists(model_name):\n","        shutil.rmtree(model_name)\n","\n","    os.mkdir(model_name)\n","\n","    for fold in range(CFG.n_splits):\n","        print(f\"fold {fold}:\")\n","\n","        train_data = train_df[train_df[\"fold\"] != fold]\n","        valid_data = train_df[train_df[\"fold\"] == fold]\n","\n","        if save_each_model == True:\n","            model_dir =  f\"{target}/{model_name}/fold_{fold}\"\n","        else:\n","            model_dir =  f\"{model_name}/fold_{fold}\"\n","\n","        csr = ContentScoreRegressor(\n","            model_name=model_name,\n","            target=target,\n","            model_dir = model_dir,\n","            hidden_dropout_prob=hidden_dropout_prob,\n","            attention_probs_dropout_prob=attention_probs_dropout_prob,\n","            max_length=max_length,\n","           )\n","\n","        csr.train(\n","            fold=fold,\n","            train_df=train_data,\n","            valid_df=valid_data,\n","            batch_size=batch_size,\n","            learning_rate=learning_rate,\n","            weight_decay=weight_decay,\n","            num_train_epochs=num_train_epochs,\n","            save_steps=save_steps,\n","        )\n","\n","def validate(\n","    train_df: pd.DataFrame,\n","    target:str,\n","    save_each_model: bool,\n","    model_name: str,\n","    hidden_dropout_prob: float,\n","    attention_probs_dropout_prob: float,\n","    max_length : int\n","    ) -> pd.DataFrame:\n","    \"\"\"predict oof data\"\"\"\n","    for fold in range(CFG.n_splits):\n","        print(f\"fold {fold}:\")\n","\n","        valid_data = train_df[train_df[\"fold\"] == fold]\n","\n","        if save_each_model == True:\n","            model_dir =  f\"{target}/{model_name}/fold_{fold}\"\n","        else:\n","            model_dir =  f\"{model_name}/fold_{fold}\"\n","\n","        csr = ContentScoreRegressor(\n","            model_name=model_name,\n","            target=target,\n","            model_dir = model_dir,\n","            hidden_dropout_prob=hidden_dropout_prob,\n","            attention_probs_dropout_prob=attention_probs_dropout_prob,\n","            max_length=max_length,\n","           )\n","\n","        pred = csr.predict(\n","            test_df=valid_data,\n","            fold=fold\n","        )\n","\n","        train_df.loc[valid_data.index, f\"{target}_pred\"] = pred\n","\n","    return train_df\n","\n","def predict(\n","    test_df: pd.DataFrame,\n","    target:str,\n","    save_each_model: bool,\n","    model_name: str,\n","    hidden_dropout_prob: float,\n","    attention_probs_dropout_prob: float,\n","    max_length : int\n","    ):\n","    \"\"\"predict using mean folds\"\"\"\n","\n","    for fold in range(CFG.n_splits):\n","        print(f\"fold {fold}:\")\n","\n","        if save_each_model == True:\n","            model_dir =  f\"{target}/{model_name}/fold_{fold}\"\n","        else:\n","            model_dir =  f\"{model_name}/fold_{fold}\"\n","\n","        csr = ContentScoreRegressor(\n","            model_name=model_name,\n","            target=target,\n","            model_dir = model_dir,\n","            hidden_dropout_prob=hidden_dropout_prob,\n","            attention_probs_dropout_prob=attention_probs_dropout_prob,\n","            max_length=max_length,\n","           )\n","\n","        pred = csr.predict(\n","            test_df=test_df,\n","            fold=fold\n","        )\n","\n","        test_df[f\"{target}_pred_{fold}\"] = pred\n","\n","    test_df[f\"{target}\"] = test_df[[f\"{target}_pred_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)\n","\n","    return test_df"],"metadata":{"trusted":true,"id":"8AYjFX2Y46eZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for target in [\"content\", \"wording\"]:\n","    train_by_fold(\n","        train,\n","        model_name=CFG.model_name,\n","        save_each_model=False,\n","        target=target,\n","        learning_rate=CFG.learning_rate,\n","        hidden_dropout_prob=CFG.hidden_dropout_prob,\n","        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n","        weight_decay=CFG.weight_decay,\n","        num_train_epochs=CFG.num_train_epochs,\n","        n_splits=CFG.n_splits,\n","        batch_size=CFG.batch_size,\n","        save_steps=CFG.save_steps,\n","        max_length=CFG.max_length\n","    )\n","\n","\n","    train = validate(\n","        train,\n","        target=target,\n","        save_each_model=False,\n","        model_name=CFG.model_name,\n","        hidden_dropout_prob=CFG.hidden_dropout_prob,\n","        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n","        max_length=CFG.max_length\n","    )\n","\n","    rmse = mean_squared_error(train[target], train[f\"{target}_pred\"], squared=False)\n","    print(f\"cv {target} rmse: {rmse}\")\n","\n","    test = predict(\n","        test,\n","        target=target,\n","        save_each_model=False,\n","        model_name=CFG.model_name,\n","        hidden_dropout_prob=CFG.hidden_dropout_prob,\n","        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n","        max_length=CFG.max_length\n","    )"],"metadata":{"trusted":true,"id":"unqqgNjN46ea"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train.head()"],"metadata":{"trusted":true,"id":"DMOG5jUf46ea"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## LGBM model"],"metadata":{"id":"RGZX7WYV46ea"}},{"cell_type":"code","source":["targets = [\"content\", \"wording\"]\n","\n","drop_columns = [\"fold\", \"student_id\", \"prompt_id\", \"text\", \"fixed_summary_text\",\n","                \"prompt_question\", \"prompt_title\",\n","                \"prompt_text\"\n","               ] + targets"],"metadata":{"trusted":true,"id":"mFozsBhZ46ea"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_dict = {}\n","\n","for target in targets:\n","    models = []\n","\n","    for fold in range(CFG.n_splits):\n","\n","        X_train_cv = train[train[\"fold\"] != fold].drop(columns=drop_columns)\n","        y_train_cv = train[train[\"fold\"] != fold][target]\n","\n","        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n","        y_eval_cv = train[train[\"fold\"] == fold][target]\n","\n","        dtrain = lgb.Dataset(X_train_cv, label=y_train_cv)\n","        dval = lgb.Dataset(X_eval_cv, label=y_eval_cv)\n","\n","        params = {\n","            'boosting_type': 'gbdt',\n","            'random_state': 42,\n","            'objective': 'regression',\n","            'metric': 'rmse',\n","            'learning_rate': 0.048,\n","            'max_depth': 4,  #3\n","            'lambda_l1': 0.0,\n","            'lambda_l2': 0.011\n","        }\n","\n","        evaluation_results = {}\n","        model = lgb.train(params,\n","                          num_boost_round=10000,\n","                            #categorical_feature = categorical_features,\n","                          valid_names=['train', 'valid'],\n","                          train_set=dtrain,\n","                          valid_sets=dval,\n","                          callbacks=[\n","                              lgb.early_stopping(stopping_rounds=30, verbose=True),\n","                               lgb.log_evaluation(100),\n","                              lgb.callback.record_evaluation(evaluation_results)\n","                            ],\n","                          )\n","        models.append(model)\n","\n","    model_dict[target] = models"],"metadata":{"trusted":true,"id":"VmnKYnM_46ea"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## CV Score"],"metadata":{"id":"MRWvrfZu46ea"}},{"cell_type":"code","source":["# cv\n","rmses = []\n","\n","for target in targets:\n","    models = model_dict[target]\n","\n","    preds = []\n","    trues = []\n","\n","    for fold, model in enumerate(models):\n","        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n","        y_eval_cv = train[train[\"fold\"] == fold][target]\n","\n","        pred = model.predict(X_eval_cv)\n","\n","        trues.extend(y_eval_cv)\n","        preds.extend(pred)\n","\n","    rmse = np.sqrt(mean_squared_error(trues, preds))\n","    print(f\"{target}_rmse : {rmse}\")\n","    rmses = rmses + [rmse]\n","\n","print(f\"mcrmse : {sum(rmses) / len(rmses)}\")"],"metadata":{"trusted":true,"id":"5ctBAxBD46ea"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Predict"],"metadata":{"id":"Mg1CuXn_46ea"}},{"cell_type":"code","source":["drop_columns = [\n","                #\"fold\",\n","                \"student_id\", \"prompt_id\", \"text\", \"fixed_summary_text\",\n","                \"prompt_question\", \"prompt_title\",\n","                \"prompt_text\",\n","                \"input\"\n","               ] + [\n","                f\"content_pred_{i}\" for i in range(CFG.n_splits)\n","                ] + [\n","                f\"wording_pred_{i}\" for i in range(CFG.n_splits)\n","                ]"],"metadata":{"trusted":true,"id":"R_Gj0xxM46ea"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_dict = {}\n","for target in targets:\n","    models = model_dict[target]\n","    preds = []\n","\n","    for fold, model in enumerate(models):\n","        X_eval_cv = test.drop(columns=drop_columns)\n","\n","        pred = model.predict(X_eval_cv)\n","        preds.append(pred)\n","\n","    pred_dict[target] = preds"],"metadata":{"trusted":true,"id":"PUsSO62e46ea"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for target in targets:\n","    preds = pred_dict[target]\n","    for i, pred in enumerate(preds):\n","        test[f\"{target}_pred_{i}\"] = pred\n","\n","    test[target] = test[[f\"{target}_pred_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)"],"metadata":{"trusted":true,"id":"H4OUHpy046ea"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test"],"metadata":{"trusted":true,"id":"IL8mu-pV46eb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Create Submission file"],"metadata":{"id":"HnjZzdWm46eb"}},{"cell_type":"code","source":["sample_submission"],"metadata":{"trusted":true,"id":"825NkOl046eb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test[[\"student_id\", \"content\", \"wording\"]].to_csv(\"submission.csv\", index=False)"],"metadata":{"trusted":true,"id":"_hgSMpGs46eb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Summary\n","\n","CV result is like this.\n","\n","| | content rmse |wording rmse | mcrmse | LB| |\n","| -- | -- | -- | -- | -- | -- |\n","|baseline| 0.494 | 0.630 | 0.562 | 0.509 | [link](https://www.kaggle.com/code/tsunotsuno/debertav3-baseline-content-and-wording-models)|\n","| use title and question field | 0.476| 0.619 | 0.548 | 0.508 | [link](https://www.kaggle.com/code/tsunotsuno/debertav3-w-prompt-title-question-fields) |\n","| Debertav3 + LGBM | 0.451 | 0.591 | 0.521 | 0.461 | [link](https://www.kaggle.com/code/tsunotsuno/debertav3-lgbm-with-feature-engineering) |\n","| Debertav3 + LGBM with spell autocorrect | 0.448 | 0.581 | 0.514 | 0.459 |nogawanogawa's original code\n","| Debertav3 + LGBM with spell autocorrect and tuning | 0.442 | 0.566 | 0.504 | 0.453 | this notebook |\n","\n","The CV values improved slightly, and the LB value is improved."],"metadata":{"id":"N9Y9s-8l46eb"}}]}